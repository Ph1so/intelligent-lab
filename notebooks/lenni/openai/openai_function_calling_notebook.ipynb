{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI function calling notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docs: https://platform.openai.com/docs/guides/function-calling\n",
    "More examples: https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models\n",
    "\n",
    "Basics of function calling:\n",
    "* The function calling feature basically compels the model to output a JSON object containing arguments to call one or many functions. It does not actually call the function. \n",
    "* By adjusting the `tool_choice` arg, you can force the model to always call one or more functions, always call a specific function, or force the model only to generate a user facing message.\n",
    "\n",
    "Basic steps for function calling:\n",
    "1. Call the model with user query and a set of functions in the `functions` parameter\n",
    "2. The model can choose to call one or more functions and will output a stringified JSON object. The model may hallucinate parameters.\n",
    "3. Parse the JSON and call your function with the provided arguments, if they exist. \n",
    "4. Can call the model again appending the function response and let the model summarize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's write a tool (function) that generates Opentrons Python code based on a natural language command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_deck_state = {\n",
    "    \"pipettes\": {\n",
    "        \"left\": {\"type\": \"p300_single\", \"tip_racks\": [\"1\"]},\n",
    "        \"right\": {\"type\": \"p20_multi\", \"tip_racks\": [\"4\", \"5\"]}\n",
    "    },\n",
    "    \"modules\": {\n",
    "        \"1\": \"temperature module\",\n",
    "        \"3\": \"magnetic module\"\n",
    "    },\n",
    "    \"labware\": {\n",
    "        \"1\": \"opentrons_96_tiprack_300ul\",\n",
    "        \"2\": \"corning_96_wellplate_360ul_flat\",\n",
    "        \"3\": \"nest_96_wellplate_100ul_pcr_full_skirt\",\n",
    "        \"4\": \"opentrons_96_tiprack_20ul\",\n",
    "        \"5\": \"opentrons_96_tiprack_20ul\",\n",
    "        \"6\": \"nest_12_reservoir_15ml\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"generate_opentrons_code\",\n",
    "            \"description\": \"Generate Python code for Opentrons OT-2 robot based on a natural language command. Use the default deck state unless the contents of the command suggest a different deck state, in which case override the defaults.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"command\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The natural language command to be translated into Opentrons Python code\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"command\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_opentrons_code(command):\n",
    "    # Always use the default_deck_state\n",
    "    deck_state = default_deck_state\n",
    "    \n",
    "    # Here, you would implement the logic to generate the code\n",
    "    # using the command and the deck_state\n",
    "    \n",
    "    generated_code = f\"\"\"\n",
    "# Generated Opentrons code for: {command}\n",
    "# Using default deck state: {json.dumps(deck_state, indent=2)}\n",
    "\n",
    "from opentrons import protocol_api\n",
    "\n",
    "metadata = {{'apiLevel': '2.13'}}\n",
    "\n",
    "def run(protocol: protocol_api.ProtocolContext):\n",
    "    # TODO: Implement the steps to execute the command\n",
    "    # This would involve translating the natural language command\n",
    "    # into specific Opentrons API calls, using the default deck state\n",
    "    pass\n",
    "\"\"\"\n",
    "    return generated_code\n",
    "\n",
    "available_functions = {\n",
    "    \"generate_opentrons_code\": generate_opentrons_code\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an AI assistant that helps translate natural language commands into Opentrons Python code. Always use the provided default deck state unless the user explicitly specifies changes to it.\"},\n",
    "    {\"role\": \"system\", \"content\": f\"Default deck state: {default_deck_state}\"},\n",
    "    {\"role\": \"user\", \"content\": \"I want to transfer 100 µL from well A1 to well B1 on a 96-well plate in slot 2.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_uTWaZ9YqOb9YGPAMsq0H61v9', function=Function(arguments='{\"command\":\"transfer 100 µL from well A1 to well B1 on a 96-well plate in slot 2\"}', name='generate_opentrons_code'), type='function')])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message = response.choices[0].message\n",
    "response_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break down the initial response message from the model. \n",
    "* `content=None`: This means the assistant didn't generate any text content and instead decided to call a function.\n",
    "* `function_call=None`: This is depreciated and has been replaced by `tool_calls`\n",
    "* `tool_calls=[...]`: This is the key part. Inside, we have a `ChatCompletionMessageToolCall` object the a unique `id`, a `function` entry with details about the function being called, and `type=function` for the type of tool call. \n",
    "* The `Function` object contains the name of the function (`name='generate_opentrons_code'`) and `arguments={\"command\": \"...\"}` – a JSON string containing arguments for the function. These args can be hallucinated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageToolCall(id='call_uTWaZ9YqOb9YGPAMsq0H61v9', function=Function(arguments='{\"command\":\"transfer 100 µL from well A1 to well B1 on a 96-well plate in slot 2\"}', name='generate_opentrons_code'), type='function')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls = response_message.tool_calls\n",
    "tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `response_message.tool_calls` returns `None` if no tools were called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Opentrons Code:\n",
      "\n",
      "# Generated Opentrons code for: transfer 100 µL from well A1 to well B1 on a 96-well plate in slot 2\n",
      "# Using default deck state: {\n",
      "  \"pipettes\": {\n",
      "    \"left\": {\n",
      "      \"type\": \"p300_single\",\n",
      "      \"tip_racks\": [\n",
      "        \"1\"\n",
      "      ]\n",
      "    },\n",
      "    \"right\": {\n",
      "      \"type\": \"p20_multi\",\n",
      "      \"tip_racks\": [\n",
      "        \"4\",\n",
      "        \"5\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"modules\": {\n",
      "    \"1\": \"temperature module\",\n",
      "    \"3\": \"magnetic module\"\n",
      "  },\n",
      "  \"labware\": {\n",
      "    \"1\": \"opentrons_96_tiprack_300ul\",\n",
      "    \"2\": \"corning_96_wellplate_360ul_flat\",\n",
      "    \"3\": \"nest_96_wellplate_100ul_pcr_full_skirt\",\n",
      "    \"4\": \"opentrons_96_tiprack_20ul\",\n",
      "    \"5\": \"opentrons_96_tiprack_20ul\",\n",
      "    \"6\": \"nest_12_reservoir_15ml\"\n",
      "  }\n",
      "}\n",
      "\n",
      "from opentrons import protocol_api\n",
      "\n",
      "metadata = {'apiLevel': '2.13'}\n",
      "\n",
      "def run(protocol: protocol_api.ProtocolContext):\n",
      "    # TODO: Implement the steps to execute the command\n",
      "    # This would involve translating the natural language command\n",
      "    # into specific Opentrons API calls, using the default deck state\n",
      "    pass\n",
      "\n",
      "\n",
      "Explanation of the generated code:\n",
      "```python\n",
      "from opentrons import protocol_api\n",
      "\n",
      "metadata = {'apiLevel': '2.13'}\n",
      "\n",
      "def run(protocol: protocol_api.ProtocolContext):\n",
      "    # Load labware\n",
      "    tip_rack = protocol.load_labware('opentrons_96_tiprack_300ul', '1')\n",
      "    plate = protocol.load_labware('corning_96_wellplate_360ul_flat', '2')\n",
      "    \n",
      "    # Load pipette\n",
      "    pipette = protocol.load_instrument('p300_single', 'left', tip_racks=[tip_rack])\n",
      "    \n",
      "    # Transfer 100 µL from well A1 to well B1\n",
      "    pipette.pick_up_tip()\n",
      "    pipette.transfer(100, plate['A1'], plate['B1'], new_tip='never')\n",
      "    pipette.drop_tip()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "if tool_calls:\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "        \n",
    "        if function_name in available_functions:\n",
    "            function_response = available_functions[function_name](**function_args)\n",
    "            print(f\"Generated Opentrons Code:\\n{function_response}\")\n",
    "            \n",
    "            messages.append({\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response\n",
    "            })\n",
    "    \n",
    "    # Get a new response from the model to explain the generated code\n",
    "    second_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    \n",
    "    print(\"\\nExplanation of the generated code:\")\n",
    "    print(second_response.choices[0].message.content)\n",
    "else:\n",
    "    print(response_message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent-lab-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
