{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph notebook 2\n",
    "https://langchain-ai.github.io/langgraph/\n",
    "\n",
    "Building agents from graphs\n",
    "\n",
    "In this notebook we first have a smaller model \"rephrase\" the user command before passing it to a bigger model. We also let the user specify a default config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from typing import TypedDict, Dict, List, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage, BaseMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    default_config: str\n",
    "    processed_command: str\n",
    "    awaiting_human_input: bool\n",
    "    current_code: str\n",
    "    code_to_run: str\n",
    "\n",
    "# Define Opentrons-specific models\n",
    "class PipetteInfo(BaseModel):\n",
    "    type: str\n",
    "    tip_rack: Optional[str] = None\n",
    "\n",
    "class OpentronsDeckState(BaseModel):\n",
    "    \"\"\"Information about the current state of the Opentrons deck.\"\"\"\n",
    "    pipettes: Dict[str, str] = Field(default_factory=dict, description=\"Pipettes attached to the robot, e.g., {'left': 'p300_single', 'right': 'p1000_multi'}\")\n",
    "    labware: Dict[str, str] = Field(default_factory=dict, description=\"Labware on the deck, e.g., {'1': 'opentrons_24_tuberack_eppendorf_1.5ml_safelock_snapcap'}\")\n",
    "    tip_racks: Dict[str, str] = Field(default_factory=dict, description=\"Tip racks on the deck, e.g., {'2': 'opentrons_96_tiprack_300ul'}\")\n",
    "    modules: Dict[str, str] = Field(default_factory=dict, description=\"Modules attached to the deck, e.g., {'7': 'thermocycler'}\")\n",
    "\n",
    "class OpentronsInstructions(BaseModel):\n",
    "    \"\"\"Flexible instructions for Opentrons liquid handling tasks.\"\"\"\n",
    "    workflow: List[Dict[str, Any]]  # A list of steps in the workflow\n",
    "    deck_state: OpentronsDeckState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_processing_template = \"\"\"\n",
    "Analyze the user's Opentrons liquid handling command and provide a structured summary. Your response should be in YAML format with the following structure:\n",
    "\n",
    "command: \"A clear, specific restatement of the user's command\"\n",
    "task_breakdown:\n",
    "  - \"Step 1: ...\"\n",
    "  - \"Step 2: ...\"\n",
    "  - ...\n",
    "required_resources:\n",
    "  pipettes: []\n",
    "  labware: []\n",
    "  modules: []\n",
    "  reagents: []\n",
    "variables_to_specify:\n",
    "  - \"Variable 1: ...\"\n",
    "  - \"Variable 2: ...\"\n",
    "  - ...\n",
    "\n",
    "Focus on identifying all necessary components and variables crucial for task execution. Use Opentrons-specific language in the task breakdown. Only include variables that are critical and not specified in the original command.\n",
    "\n",
    "Examples:\n",
    "\n",
    "User input: \"Dilute all of the wells on the 96-well plate on deck slot 3 with 10 uL of water from a water container in well 1a of the 24-well metal block on top of the temperature controller. 20 uL tip rack is on deck slot 2 and the 20 uL pipette is mounted on the left side.\"\n",
    "\n",
    "Output:\n",
    "command: \"Dilute each well of a 96-well plate with 10 µL of water, using a 20 µL pipette and a temperature-controlled water source\"\n",
    "task_breakdown:\n",
    "  - \"1. Load labware onto the deck: 96-well plate, 24-well aluminum block, and 20 µL tip rack\"\n",
    "  - \"2. Load 20 µL single-channel pipette on the left mount\"\n",
    "  - \"3. Load temperature module and place 24-well metal block on it\"\n",
    "  - \"4. Load liquid (water) to well A1 of the 24-well metal block\"\n",
    "  - \"5. For each well in the 96-well plate:\"\n",
    "  - \"   a. Pick up a 20 µL tip\"\n",
    "  - \"   b. Aspirate 10 µL of water from well A1 of the 24-well block\"\n",
    "  - \"   c. Dispense 10 µL into the current well of the 96-well plate\"\n",
    "  - \"   d. Drop the used tip\"\n",
    "required_resources:\n",
    "  pipettes:\n",
    "    - \"20 µL single-channel (left)\"\n",
    "  labware:\n",
    "    - \"96-well plate\"\n",
    "    - \"24-well aluminum block\"\n",
    "    - \"20 µL tip rack\"\n",
    "  modules:\n",
    "    - \"Temperature module\"\n",
    "  reagents:\n",
    "    - \"Water\"\n",
    "variables_to_specify:\n",
    "  - \"Total volume of water needed for dilution\"\n",
    "\n",
    "User input: \"Transfer 5 uL from well A1 to B1 in the same plate and dispose of the tip\"\n",
    "\n",
    "Output:\n",
    "command: \"Transfer 5 µL from well A1 to well B1 within a single plate using a single-channel pipette, then dispose of the tip\"\n",
    "task_breakdown:\n",
    "  - \"1. Load labware onto the deck: plate and tip rack\"\n",
    "  - \"2. Load single-channel pipette (≤10 µL capacity)\"\n",
    "  - \"3. Pick up a pipette tip\"\n",
    "  - \"4. Aspirate 5 µL from well A1 of the plate\"\n",
    "  - \"5. Dispense 5 µL into well B1 of the same plate\"\n",
    "  - \"6. Drop the used tip in the trash\"\n",
    "required_resources:\n",
    "  pipettes:\n",
    "    - \"Single-channel pipette (≤10 µL capacity)\"\n",
    "  labware:\n",
    "    - \"Plate\"\n",
    "    - \"Tip rack\"\n",
    "  modules: []\n",
    "  reagents: []\n",
    "variables_to_specify:\n",
    "  - \"Plate location on deck\"\n",
    "  - \"Tip rack location on deck\"\n",
    "  - \"Pipette mount position (left or right)\"\n",
    "\n",
    "Provide a similar structured output for the given user input.\n",
    "\"\"\"\n",
    "\n",
    "get_info_template = \"\"\"\n",
    "Your task is to determine if more information is needed to execute the Opentrons liquid handling task. Review the rephrased command, task breakdown, required resources, variables to specify, default configuration, and conversation history.\n",
    "\n",
    "Analyze the information for:\n",
    "- Missing required resources\n",
    "- Unspecified critical variables (e.g., volumes, labware locations, pipette types and positions)\n",
    "- Compatibility issues between specified labware and pipettes\n",
    "- Any crucial information gaps that could prevent the protocol from running\n",
    "\n",
    "If critical information is missing, formulate 1-3 clear, concise questions to gather this information from the user. Focus only on what's absolutely necessary for the protocol to run correctly.\n",
    "\n",
    "If all critical information is available, use the OpentronsInstructions tool to generate instructions.\n",
    "\n",
    "Your response should be in one of these two formats:\n",
    "1. A list of questions, each on a new line, starting with \"Q: \". For example:\n",
    "   Q: What is the specific model of the 96-well plate?\n",
    "   Q: What is the configuration of the thermocycler plate?\n",
    "\n",
    "2. Or, if all information is complete, use the OpentronsInstructions tool to structure the information. Here's how to use the tool:\n",
    "\n",
    "1. Only use the tool when you have gathered ALL necessary information for the task.\n",
    "2. Structure the information into 'workflow' and 'deck_state' as defined by the tool.\n",
    "3. For 'workflow', provide a list of discrete steps, each with an 'operation' and relevant parameters.\n",
    "4. For 'deck_state', include information about pipettes, labware, tip_racks, and modules.\n",
    "5. If any information is assumed or inferred, clearly state these assumptions before using the tool.\n",
    "6. Do not include any fields or structures not defined in the OpentronsInstructions tool.\n",
    "\n",
    "Avoid asking about:\n",
    "- Exact labware models unless crucial for the protocol\n",
    "- Minor details that can be assumed based on standard laboratory practices\n",
    "- Information already provided in the default configuration unless there's a clear conflict\n",
    "\n",
    "Remember, output ONLY the questions or the tool use instruction, without any additional explanation or analysis.\n",
    "\"\"\"\n",
    "\n",
    "code_gen_template = \"\"\"\n",
    "Based on the following Opentrons workflow and deck state, generate Python code using the Opentrons API:\n",
    "\n",
    "{instructions}\n",
    "\n",
    "Ensure the code follows best practices for the Opentrons API, includes proper error handling, and is well-commented for clarity.\n",
    "\n",
    "Output just the commented code without any explanations or additional text. The user should be able to copy and paste the code into their Python script and run it without any modifications.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up models and chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_processing_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", initial_processing_template),\n",
    "    (\"human\", \"{input}\\n\\nDefault Opentrons config:\\n{default_config}\")\n",
    "])\n",
    "initial_processing_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "initial_processing_chain = initial_processing_prompt | initial_processing_model\n",
    "\n",
    "get_info_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", get_info_template),\n",
    "    (\"human\", \"Initial command:\\n{initial_user_command}\\n\\nProcessed command:\\n{processed_command}\\n\\nDefault config:\\n{default_config}\"),\n",
    "    MessagesPlaceholder(variable_name=\"follow_up_messages\"),\n",
    "])\n",
    "get_info_model = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "get_info_model_with_tool = get_info_model.bind_tools([OpentronsInstructions])\n",
    "get_info_chain = (\n",
    "    {\n",
    "        \"initial_user_command\": lambda x: x[\"initial_user_command\"],\n",
    "        \"processed_command\": lambda x: x[\"processed_command\"],\n",
    "        \"default_config\": lambda x: x[\"default_config\"],\n",
    "        \"follow_up_messages\": lambda x: x[\"follow_up_messages\"]\n",
    "    }\n",
    "    | get_info_prompt\n",
    "    | get_info_model_with_tool\n",
    ")\n",
    "\n",
    "code_gen_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", code_gen_template),\n",
    "    (\"human\", \"{instructions}\")\n",
    "])\n",
    "code_gen_model = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "code_gen_chain = code_gen_prompt | code_gen_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define node functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_processing_node(state: AgentState):\n",
    "    processed_command = initial_processing_chain.invoke({\n",
    "        \"input\": state[\"messages\"][-1].content,\n",
    "        \"default_config\": state[\"default_config\"]\n",
    "    })\n",
    "    return {\n",
    "        \"processed_command\": processed_command.content,\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=processed_command.content)]\n",
    "    }\n",
    "\n",
    "def get_info_node(state: AgentState):\n",
    "    initial_user_command = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "    follow_up_messages = state[\"messages\"][2:] if len(state[\"messages\"]) > 2 else []\n",
    "    \n",
    "    result = get_info_chain.invoke({\n",
    "        \"initial_user_command\": initial_user_command,\n",
    "        \"processed_command\": state[\"processed_command\"],\n",
    "        \"default_config\": state[\"default_config\"],\n",
    "        \"follow_up_messages\": follow_up_messages\n",
    "    })\n",
    "\n",
    "    if isinstance(result, AIMessage) and result.tool_calls:\n",
    "        # If the content is empty, add a default message\n",
    "        if not result.content:\n",
    "            result.content = \"Using the OpentronsInstructions tool to generate the protocol.\"\n",
    "        \n",
    "        # Handle tool calls\n",
    "        tool_messages = []\n",
    "        for tool_call in result.tool_calls:\n",
    "            if tool_call['name'] == \"OpentronsInstructions\":\n",
    "                # Execute the OpentronsInstructions tool\n",
    "                # tool_result = OpentronsInstructions(**tool_call['args'])\n",
    "                tool_message = ToolMessage(\n",
    "                    content=str(tool_call['args']),\n",
    "                    tool_call_id=tool_call['id'],\n",
    "                    name=\"OpentronsInstructions\"\n",
    "                )\n",
    "                tool_messages.append(tool_message)\n",
    "        \n",
    "        print(f\"\\n================================== AI tool call ==================================\\n{[msg.content for msg in tool_messages]}\\n\")\n",
    "        return {\"messages\": state[\"messages\"] + [result] + tool_messages, \"awaiting_human_input\": False}\n",
    "    elif isinstance(result, (str, AIMessage)):\n",
    "        new_message = result if isinstance(result, AIMessage) else AIMessage(content=result)\n",
    "        print(f\"\\n================================== AI message ==================================\\n{new_message.content}\\n\")\n",
    "        user_input = input(\"User (q/Q to quit): \")\n",
    "        print(f\"\\n================================== Human message ==================================\\n{user_input}\\n\")\n",
    "        return {\n",
    "            \"messages\": state[\"messages\"] + [new_message, HumanMessage(content=user_input)],\n",
    "            \"awaiting_human_input\": False\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected result type: {type(result)}\")\n",
    "    \n",
    "def code_gen_node(state: AgentState):\n",
    "    # TODO make sure the code_gen module has access to the initial user command or just generally optimize this.\n",
    "\n",
    "    instructions = next(msg.content for msg in reversed(state[\"messages\"]) if isinstance(msg, ToolMessage))\n",
    "    code = code_gen_chain.invoke({\"instructions\": instructions})\n",
    "    print(f\"\\n================================== Current code ==================================\\n{code.content}\\n\")\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=code.content)],\n",
    "        \"awaiting_human_input\": True,\n",
    "        \"current_code\": code.content\n",
    "        }\n",
    "\n",
    "def code_refinement_node(state: AgentState):\n",
    "    # Find the index of the OpentronsInstructions tool message\n",
    "    # start_index = next((i for i, msg in enumerate(state[\"messages\"]) \n",
    "    #                     if isinstance(msg, ToolMessage) and msg.name == \"OpentronsInstructions\"), None)\n",
    "    \n",
    "    # if start_index is None:\n",
    "    #     return {\"messages\": state[\"messages\"], \"awaiting_human_input\": False}\n",
    "    start_index = 0\n",
    "\n",
    "    relevant_messages = state[\"messages\"][start_index:]\n",
    "    \n",
    "    # Get the current code from the state\n",
    "    current_code = state.get(\"current_code\")\n",
    "    \n",
    "    user_input = input(\"Provide feedback on the code (or type 'ACCEPT' to finish): \")\n",
    "    \n",
    "    if user_input.upper() == 'ACCEPT':\n",
    "        return {\n",
    "            \"messages\": state[\"messages\"],\n",
    "            \"awaiting_human_input\": False,\n",
    "            \"code_to_run\": current_code  # Store the approved code\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n================================== Human message ==================================\\n{user_input}\\n\")\n",
    "\n",
    "    # Use the existing code_gen_model for refinement, including all relevant messages\n",
    "    system_message = SystemMessage(content=code_gen_template)\n",
    "    refined_code = code_gen_model.invoke([system_message] + relevant_messages + [HumanMessage(content=user_input)])\n",
    "    \n",
    "    print(f\"\\n================================== Current Code ==================================\\n{refined_code.content}\\n\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [HumanMessage(content=user_input), refined_code],\n",
    "        \"awaiting_human_input\": True,\n",
    "        \"current_code\": refined_code.content  # Update the current code\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "\n",
    "workflow.add_node(\"initial_processing\", initial_processing_node)\n",
    "workflow.add_node(\"get_info\", get_info_node)\n",
    "workflow.add_node(\"code_gen\", code_gen_node)\n",
    "workflow.add_node(\"code_refinement\", code_refinement_node)  # New node\n",
    "\n",
    "workflow.add_edge(START, \"initial_processing\")\n",
    "workflow.add_edge(\"initial_processing\", \"get_info\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"get_info\",\n",
    "    lambda x: \"code_gen\" if any(isinstance(m, ToolMessage) for m in x[\"messages\"]) else \"get_info\"\n",
    ")\n",
    "workflow.add_edge(\"code_gen\", \"code_refinement\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"code_refinement\",\n",
    "    lambda x: \"code_refinement\" if x[\"awaiting_human_input\"] else END\n",
    ")\n",
    "\n",
    "# Compile the graph\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# Visualization (if in a Jupyter environment)\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main execution loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================== Human message ==================================\n",
      "Please set the temperature of the thermocycler in deck slot 7 to 90 degC. After it has reached that temp, please transfer 20 uL from well 1A of a 96 well plate in slot 1 to the plate on the thermocycler (same well). Blow out tip and then discard the tip.\n",
      "\n",
      "\n",
      "================================== AI message ==================================\n",
      "Q: What is the specific model of the thermocycler plate?\n",
      "Q: Where are the tip racks located on the deck?\n",
      "\n",
      "\n",
      "================================== Human message ==================================\n",
      "96 well plate corning. 300 uL tips in deck slot 2.\n",
      "\n",
      "\n",
      "================================== AI tool call ==================================\n",
      "[\"{'deck_state': {'pipettes': {'left': 'p300_single'}, 'labware': {'1': '96-well plate corning', '7': 'thermocyclerModuleV2'}, 'tip_racks': {'2': 'opentrons_96_tiprack_300ul'}, 'modules': {'7': 'thermocyclerModuleV2'}}, 'workflow': [{'operation': 'load_labware', 'labware': '96-well plate corning', 'slot': '1'}, {'operation': 'load_module', 'module': 'thermocyclerModuleV2', 'slot': '7'}, {'operation': 'set_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'wait_until_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'load_pipette', 'pipette': 'p300_single', 'mount': 'left'}, {'operation': 'pick_up_tip', 'pipette': 'p300_single', 'tiprack': 'opentrons_96_tiprack_300ul', 'well': 'A1'}, {'operation': 'aspirate', 'pipette': 'p300_single', 'volume': 20, 'labware': '96-well plate corning', 'well': 'A1'}, {'operation': 'dispense', 'pipette': 'p300_single', 'volume': 20, 'labware': 'thermocyclerModuleV2', 'well': 'A1'}, {'operation': 'blow_out', 'pipette': 'p300_single', 'labware': 'opentrons_96_tiprack_300ul', 'well': 'A1'}, {'operation': 'drop_tip', 'pipette': 'p300_single', 'tiprack': 'opentrons_96_tiprack_300ul', 'well': 'A1'}]}\"]\n",
      "\n",
      "\n",
      "================================== AI message ==================================\n",
      "```python\n",
      "from opentrons import protocol_api\n",
      "\n",
      "# Metadata is a dictionary of data that is read by the server and returned to the opentrons app. \n",
      "# Update these fields with your details.\n",
      "metadata = {\n",
      "    'protocolName': 'My Protocol',\n",
      "    'author': 'Your Name',\n",
      "    'description': 'Simple protocol to get started using OT2',\n",
      "    'apiLevel': '2.10'\n",
      "}\n",
      "\n",
      "def run(protocol: protocol_api.ProtocolContext):\n",
      "\n",
      "    # labware\n",
      "    plate = protocol.load_labware('96-well plate corning', '1')\n",
      "    tiprack = protocol.load_labware('opentrons_96_tiprack_300ul', '2')\n",
      "\n",
      "    # module\n",
      "    thermocycler = protocol.load_module('thermocyclerModuleV2', '7')\n",
      "\n",
      "    # pipette\n",
      "    pipette = protocol.load_instrument('p300_single', 'left', tip_racks=[tiprack])\n",
      "\n",
      "    # Set the thermocycler's temperature to 90C and wait until it reaches the target temperature\n",
      "    thermocycler.set_temperature(90)\n",
      "    thermocycler.await_temperature(90)\n",
      "\n",
      "    # Pick up a tip\n",
      "    pipette.pick_up_tip(tiprack.wells_by_name()['A1'])\n",
      "\n",
      "    # Aspirate 20uL from the 96-well plate\n",
      "    pipette.aspirate(20, plate.wells_by_name()['A1'])\n",
      "\n",
      "    # Dispense 20uL into the thermocycler\n",
      "    pipette.dispense(20, thermocycler.wells_by_name()['A1'])\n",
      "\n",
      "    # Blow out the remaining liquid in the pipette into the tip rack\n",
      "    pipette.blow_out(tiprack.wells_by_name()['A1'])\n",
      "\n",
      "    # Drop the tip back into the tip rack\n",
      "    pipette.drop_tip(tiprack.wells_by_name()['A1'])\n",
      "```\n",
      "\n",
      "\n",
      "code_refinement_node: relevant_messages\n",
      " [HumanMessage(content='Please set the temperature of the thermocycler in deck slot 7 to 90 degC. After it has reached that temp, please transfer 20 uL from well 1A of a 96 well plate in slot 1 to the plate on the thermocycler (same well). Blow out tip and then discard the tip.'), AIMessage(content='```yaml\\ncommand: \"Set the thermocycler temperature to 90 °C, then transfer 20 µL from well 1A of a 96-well plate in slot 1 to the same well on the thermocycler, blow out the tip, and discard it.\"\\ntask_breakdown:\\n  - \"1. Load labware onto the deck: 96-well plate in slot 1\"\\n  - \"2. Load the thermocycler module in deck slot 7\"\\n  - \"3. Set the thermocycler temperature to 90 °C\"\\n  - \"4. Wait until the thermocycler reaches 90 °C\"\\n  - \"5. Load a pipette (p300_single) on the left mount\"\\n  - \"6. Pick up a pipette tip\"\\n  - \"7. Aspirate 20 µL from well 1A of the 96-well plate in slot 1\"\\n  - \"8. Dispense 20 µL into well 1A of the thermocycler plate\"\\n  - \"9. Blow out the tip\"\\n  - \"10. Discard the used tip\"\\nrequired_resources:\\n  pipettes:\\n    - \"p300_single (left)\"\\n  labware:\\n    - \"96-well plate (slot 1)\"\\n  modules:\\n    - \"thermocyclerModuleV2 (slot 7)\"\\n  reagents: []\\nvariables_to_specify:\\n  - \"Thermocycler plate location on the thermocycler\"\\n```'), AIMessage(content='Q: What is the specific model of the thermocycler plate?\\nQ: Where are the tip racks located on the deck?', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 958, 'total_tokens': 985}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1a2f73e5-5a4b-48c8-bb75-fe4de5629f2a-0', usage_metadata={'input_tokens': 958, 'output_tokens': 27, 'total_tokens': 985}), HumanMessage(content='96 well plate corning. 300 uL tips in deck slot 2.'), AIMessage(content='Using the OpentronsInstructions tool to generate the protocol.', additional_kwargs={'tool_calls': [{'id': 'call_50Jlt2MFHDFRceSL6j1MYrCo', 'function': {'arguments': '{\\n  \"deck_state\": {\\n    \"pipettes\": {\\n      \"left\": \"p300_single\"\\n    },\\n    \"labware\": {\\n      \"1\": \"96-well plate corning\",\\n      \"7\": \"thermocyclerModuleV2\"\\n    },\\n    \"tip_racks\": {\\n      \"2\": \"opentrons_96_tiprack_300ul\"\\n    },\\n    \"modules\": {\\n      \"7\": \"thermocyclerModuleV2\"\\n    }\\n  },\\n  \"workflow\": [\\n    {\\n      \"operation\": \"load_labware\",\\n      \"labware\": \"96-well plate corning\",\\n      \"slot\": \"1\"\\n    },\\n    {\\n      \"operation\": \"load_module\",\\n      \"module\": \"thermocyclerModuleV2\",\\n      \"slot\": \"7\"\\n    },\\n    {\\n      \"operation\": \"set_temperature\",\\n      \"module\": \"thermocyclerModuleV2\",\\n      \"temperature\": 90\\n    },\\n    {\\n      \"operation\": \"wait_until_temperature\",\\n      \"module\": \"thermocyclerModuleV2\",\\n      \"temperature\": 90\\n    },\\n    {\\n      \"operation\": \"load_pipette\",\\n      \"pipette\": \"p300_single\",\\n      \"mount\": \"left\"\\n    },\\n    {\\n      \"operation\": \"pick_up_tip\",\\n      \"pipette\": \"p300_single\",\\n      \"tiprack\": \"opentrons_96_tiprack_300ul\",\\n      \"well\": \"A1\"\\n    },\\n    {\\n      \"operation\": \"aspirate\",\\n      \"pipette\": \"p300_single\",\\n      \"volume\": 20,\\n      \"labware\": \"96-well plate corning\",\\n      \"well\": \"A1\"\\n    },\\n    {\\n      \"operation\": \"dispense\",\\n      \"pipette\": \"p300_single\",\\n      \"volume\": 20,\\n      \"labware\": \"thermocyclerModuleV2\",\\n      \"well\": \"A1\"\\n    },\\n    {\\n      \"operation\": \"blow_out\",\\n      \"pipette\": \"p300_single\",\\n      \"labware\": \"opentrons_96_tiprack_300ul\",\\n      \"well\": \"A1\"\\n    },\\n    {\\n      \"operation\": \"drop_tip\",\\n      \"pipette\": \"p300_single\",\\n      \"tiprack\": \"opentrons_96_tiprack_300ul\",\\n      \"well\": \"A1\"\\n    }\\n  ]\\n}', 'name': 'OpentronsInstructions'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 526, 'prompt_tokens': 1009, 'total_tokens': 1535}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-518d6cee-aa4a-42f9-85db-d64a18230d20-0', tool_calls=[{'name': 'OpentronsInstructions', 'args': {'deck_state': {'pipettes': {'left': 'p300_single'}, 'labware': {'1': '96-well plate corning', '7': 'thermocyclerModuleV2'}, 'tip_racks': {'2': 'opentrons_96_tiprack_300ul'}, 'modules': {'7': 'thermocyclerModuleV2'}}, 'workflow': [{'operation': 'load_labware', 'labware': '96-well plate corning', 'slot': '1'}, {'operation': 'load_module', 'module': 'thermocyclerModuleV2', 'slot': '7'}, {'operation': 'set_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'wait_until_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'load_pipette', 'pipette': 'p300_single', 'mount': 'left'}, {'operation': 'pick_up_tip', 'pipette': 'p300_single', 'tiprack': 'opentrons_96_tiprack_300ul', 'well': 'A1'}, {'operation': 'aspirate', 'pipette': 'p300_single', 'volume': 20, 'labware': '96-well plate corning', 'well': 'A1'}, {'operation': 'dispense', 'pipette': 'p300_single', 'volume': 20, 'labware': 'thermocyclerModuleV2', 'well': 'A1'}, {'operation': 'blow_out', 'pipette': 'p300_single', 'labware': 'opentrons_96_tiprack_300ul', 'well': 'A1'}, {'operation': 'drop_tip', 'pipette': 'p300_single', 'tiprack': 'opentrons_96_tiprack_300ul', 'well': 'A1'}]}, 'id': 'call_50Jlt2MFHDFRceSL6j1MYrCo', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1009, 'output_tokens': 526, 'total_tokens': 1535}), ToolMessage(content=\"{'deck_state': {'pipettes': {'left': 'p300_single'}, 'labware': {'1': '96-well plate corning', '7': 'thermocyclerModuleV2'}, 'tip_racks': {'2': 'opentrons_96_tiprack_300ul'}, 'modules': {'7': 'thermocyclerModuleV2'}}, 'workflow': [{'operation': 'load_labware', 'labware': '96-well plate corning', 'slot': '1'}, {'operation': 'load_module', 'module': 'thermocyclerModuleV2', 'slot': '7'}, {'operation': 'set_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'wait_until_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'load_pipette', 'pipette': 'p300_single', 'mount': 'left'}, {'operation': 'pick_up_tip', 'pipette': 'p300_single', 'tiprack': 'opentrons_96_tiprack_300ul', 'well': 'A1'}, {'operation': 'aspirate', 'pipette': 'p300_single', 'volume': 20, 'labware': '96-well plate corning', 'well': 'A1'}, {'operation': 'dispense', 'pipette': 'p300_single', 'volume': 20, 'labware': 'thermocyclerModuleV2', 'well': 'A1'}, {'operation': 'blow_out', 'pipette': 'p300_single', 'labware': 'opentrons_96_tiprack_300ul', 'well': 'A1'}, {'operation': 'drop_tip', 'pipette': 'p300_single', 'tiprack': 'opentrons_96_tiprack_300ul', 'well': 'A1'}]}\", name='OpentronsInstructions', tool_call_id='call_50Jlt2MFHDFRceSL6j1MYrCo'), AIMessage(content=\"```python\\nfrom opentrons import protocol_api\\n\\n# Metadata is a dictionary of data that is read by the server and returned to the opentrons app. \\n# Update these fields with your details.\\nmetadata = {\\n    'protocolName': 'My Protocol',\\n    'author': 'Your Name',\\n    'description': 'Simple protocol to get started using OT2',\\n    'apiLevel': '2.10'\\n}\\n\\ndef run(protocol: protocol_api.ProtocolContext):\\n\\n    # labware\\n    plate = protocol.load_labware('96-well plate corning', '1')\\n    tiprack = protocol.load_labware('opentrons_96_tiprack_300ul', '2')\\n\\n    # module\\n    thermocycler = protocol.load_module('thermocyclerModuleV2', '7')\\n\\n    # pipette\\n    pipette = protocol.load_instrument('p300_single', 'left', tip_racks=[tiprack])\\n\\n    # Set the thermocycler's temperature to 90C and wait until it reaches the target temperature\\n    thermocycler.set_temperature(90)\\n    thermocycler.await_temperature(90)\\n\\n    # Pick up a tip\\n    pipette.pick_up_tip(tiprack.wells_by_name()['A1'])\\n\\n    # Aspirate 20uL from the 96-well plate\\n    pipette.aspirate(20, plate.wells_by_name()['A1'])\\n\\n    # Dispense 20uL into the thermocycler\\n    pipette.dispense(20, thermocycler.wells_by_name()['A1'])\\n\\n    # Blow out the remaining liquid in the pipette into the tip rack\\n    pipette.blow_out(tiprack.wells_by_name()['A1'])\\n\\n    # Drop the tip back into the tip rack\\n    pipette.drop_tip(tiprack.wells_by_name()['A1'])\\n```\\n\")]\n",
      "\n",
      "================================== Current Code ==================================\n",
      "```python\n",
      "from opentrons import protocol_api\n",
      "\n",
      "# Metadata is a dictionary of data that is read by the server and returned to the opentrons app. \n",
      "# Update these fields with your details.\n",
      "metadata = {\n",
      "    'protocolName': 'My Protocol',\n",
      "    'author': 'Your Name',\n",
      "    'description': 'Simple protocol to get started using OT2',\n",
      "    'apiLevel': '2.10'\n",
      "}\n",
      "\n",
      "def run(protocol: protocol_api.ProtocolContext):\n",
      "\n",
      "    # labware\n",
      "    plate = protocol.load_labware('96-well plate corning', '1')\n",
      "    tiprack = protocol.load_labware('opentrons_96_tiprack_300ul', '2')\n",
      "\n",
      "    # module\n",
      "    thermocycler = protocol.load_module('thermocyclerModuleV2', '7')\n",
      "\n",
      "    # pipette\n",
      "    pipette = protocol.load_instrument('p300_single', 'left', tip_racks=[tiprack])\n",
      "\n",
      "    # Set the thermocycler's temperature to 90C and wait until it reaches the target temperature\n",
      "    thermocycler.set_temperature(90)\n",
      "    thermocycler.await_temperature(90)\n",
      "\n",
      "    # Pick up a tip\n",
      "    pipette.pick_up_tip(tiprack.wells_by_name()['A1'])\n",
      "\n",
      "    # Aspirate 20uL from the 96-well plate\n",
      "    pipette.aspirate(20, plate.wells_by_name()['A1'])\n",
      "\n",
      "    # Dispense 20uL into the thermocycler\n",
      "    pipette.dispense(20, thermocycler.wells_by_name()['A1'])\n",
      "\n",
      "    # Blow out the remaining liquid in the pipette into the tip rack\n",
      "    pipette.blow_out(tiprack.wells_by_name()['A1'])\n",
      "\n",
      "    # Drop the tip back into the tip rack\n",
      "    pipette.drop_tip(tiprack.wells_by_name()['A1'])\n",
      "```\n",
      "\n",
      "\n",
      "\n",
      "================================== Human message ==================================\n",
      "Please drop the tip in the tip rack and the blow out should happen in the thermocycler well A1\n",
      "\n",
      "\n",
      "================================== Refined Code ==================================\n",
      "```python\n",
      "from opentrons import protocol_api\n",
      "\n",
      "# Metadata is a dictionary of data that is read by the server and returned to the opentrons app. \n",
      "# Update these fields with your details.\n",
      "metadata = {\n",
      "    'protocolName': 'My Protocol',\n",
      "    'author': 'Your Name',\n",
      "    'description': 'Simple protocol to get started using OT2',\n",
      "    'apiLevel': '2.10'\n",
      "}\n",
      "\n",
      "def run(protocol: protocol_api.ProtocolContext):\n",
      "\n",
      "    # labware\n",
      "    plate = protocol.load_labware('96-well plate corning', '1')\n",
      "    tiprack = protocol.load_labware('opentrons_96_tiprack_300ul', '2')\n",
      "\n",
      "    # module\n",
      "    thermocycler = protocol.load_module('thermocyclerModuleV2', '7')\n",
      "\n",
      "    # pipette\n",
      "    pipette = protocol.load_instrument('p300_single', 'left', tip_racks=[tiprack])\n",
      "\n",
      "    # Set the thermocycler's temperature to 90C and wait until it reaches the target temperature\n",
      "    thermocycler.set_temperature(90)\n",
      "    thermocycler.await_temperature(90)\n",
      "\n",
      "    # Pick up a tip\n",
      "    pipette.pick_up_tip(tiprack.wells_by_name()['A1'])\n",
      "\n",
      "    # Aspirate 20uL from the 96-well plate\n",
      "    pipette.aspirate(20, plate.wells_by_name()['A1'])\n",
      "\n",
      "    # Dispense 20uL into the thermocycler\n",
      "    pipette.dispense(20, thermocycler.wells_by_name()['A1'])\n",
      "\n",
      "    # Blow out the remaining liquid in the pipette into the thermocycler\n",
      "    pipette.blow_out(thermocycler.wells_by_name()['A1'])\n",
      "\n",
      "    # Drop the tip back into the tip rack\n",
      "    pipette.drop_tip()\n",
      "```\n",
      "\n",
      "code_refinement_node: relevant_messages\n",
      " [HumanMessage(content='Please set the temperature of the thermocycler in deck slot 7 to 90 degC. After it has reached that temp, please transfer 20 uL from well 1A of a 96 well plate in slot 1 to the plate on the thermocycler (same well). Blow out tip and then discard the tip.'), AIMessage(content='```yaml\\ncommand: \"Set the thermocycler temperature to 90 °C, then transfer 20 µL from well 1A of a 96-well plate in slot 1 to the same well on the thermocycler, blow out the tip, and discard it.\"\\ntask_breakdown:\\n  - \"1. Load labware onto the deck: 96-well plate in slot 1\"\\n  - \"2. Load the thermocycler module in deck slot 7\"\\n  - \"3. Set the thermocycler temperature to 90 °C\"\\n  - \"4. Wait until the thermocycler reaches 90 °C\"\\n  - \"5. Load a pipette (p300_single) on the left mount\"\\n  - \"6. Pick up a pipette tip\"\\n  - \"7. Aspirate 20 µL from well 1A of the 96-well plate in slot 1\"\\n  - \"8. Dispense 20 µL into well 1A of the thermocycler plate\"\\n  - \"9. Blow out the tip\"\\n  - \"10. Discard the used tip\"\\nrequired_resources:\\n  pipettes:\\n    - \"p300_single (left)\"\\n  labware:\\n    - \"96-well plate (slot 1)\"\\n  modules:\\n    - \"thermocyclerModuleV2 (slot 7)\"\\n  reagents: []\\nvariables_to_specify:\\n  - \"Thermocycler plate location on the thermocycler\"\\n```'), AIMessage(content='Q: What is the specific model of the thermocycler plate?\\nQ: Where are the tip racks located on the deck?', response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 958, 'total_tokens': 985}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-1a2f73e5-5a4b-48c8-bb75-fe4de5629f2a-0', usage_metadata={'input_tokens': 958, 'output_tokens': 27, 'total_tokens': 985}), HumanMessage(content='96 well plate corning. 300 uL tips in deck slot 2.'), AIMessage(content='Using the OpentronsInstructions tool to generate the protocol.', additional_kwargs={'tool_calls': [{'id': 'call_50Jlt2MFHDFRceSL6j1MYrCo', 'function': {'arguments': '{\\n  \"deck_state\": {\\n    \"pipettes\": {\\n      \"left\": \"p300_single\"\\n    },\\n    \"labware\": {\\n      \"1\": \"96-well plate corning\",\\n      \"7\": \"thermocyclerModuleV2\"\\n    },\\n    \"tip_racks\": {\\n      \"2\": \"opentrons_96_tiprack_300ul\"\\n    },\\n    \"modules\": {\\n      \"7\": \"thermocyclerModuleV2\"\\n    }\\n  },\\n  \"workflow\": [\\n    {\\n      \"operation\": \"load_labware\",\\n      \"labware\": \"96-well plate corning\",\\n      \"slot\": \"1\"\\n    },\\n    {\\n      \"operation\": \"load_module\",\\n      \"module\": \"thermocyclerModuleV2\",\\n      \"slot\": \"7\"\\n    },\\n    {\\n      \"operation\": \"set_temperature\",\\n      \"module\": \"thermocyclerModuleV2\",\\n      \"temperature\": 90\\n    },\\n    {\\n      \"operation\": \"wait_until_temperature\",\\n      \"module\": \"thermocyclerModuleV2\",\\n      \"temperature\": 90\\n    },\\n    {\\n      \"operation\": \"load_pipette\",\\n      \"pipette\": \"p300_single\",\\n      \"mount\": \"left\"\\n    },\\n    {\\n      \"operation\": \"pick_up_tip\",\\n      \"pipette\": \"p300_single\",\\n      \"tiprack\": \"opentrons_96_tiprack_300ul\",\\n      \"well\": \"A1\"\\n    },\\n    {\\n      \"operation\": \"aspirate\",\\n      \"pipette\": \"p300_single\",\\n      \"volume\": 20,\\n      \"labware\": \"96-well plate corning\",\\n      \"well\": \"A1\"\\n    },\\n    {\\n      \"operation\": \"dispense\",\\n      \"pipette\": \"p300_single\",\\n      \"volume\": 20,\\n      \"labware\": \"thermocyclerModuleV2\",\\n      \"well\": \"A1\"\\n    },\\n    {\\n      \"operation\": \"blow_out\",\\n      \"pipette\": \"p300_single\",\\n      \"labware\": \"opentrons_96_tiprack_300ul\",\\n      \"well\": \"A1\"\\n    },\\n    {\\n      \"operation\": \"drop_tip\",\\n      \"pipette\": \"p300_single\",\\n      \"tiprack\": \"opentrons_96_tiprack_300ul\",\\n      \"well\": \"A1\"\\n    }\\n  ]\\n}', 'name': 'OpentronsInstructions'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 526, 'prompt_tokens': 1009, 'total_tokens': 1535}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-518d6cee-aa4a-42f9-85db-d64a18230d20-0', tool_calls=[{'name': 'OpentronsInstructions', 'args': {'deck_state': {'pipettes': {'left': 'p300_single'}, 'labware': {'1': '96-well plate corning', '7': 'thermocyclerModuleV2'}, 'tip_racks': {'2': 'opentrons_96_tiprack_300ul'}, 'modules': {'7': 'thermocyclerModuleV2'}}, 'workflow': [{'operation': 'load_labware', 'labware': '96-well plate corning', 'slot': '1'}, {'operation': 'load_module', 'module': 'thermocyclerModuleV2', 'slot': '7'}, {'operation': 'set_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'wait_until_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'load_pipette', 'pipette': 'p300_single', 'mount': 'left'}, {'operation': 'pick_up_tip', 'pipette': 'p300_single', 'tiprack': 'opentrons_96_tiprack_300ul', 'well': 'A1'}, {'operation': 'aspirate', 'pipette': 'p300_single', 'volume': 20, 'labware': '96-well plate corning', 'well': 'A1'}, {'operation': 'dispense', 'pipette': 'p300_single', 'volume': 20, 'labware': 'thermocyclerModuleV2', 'well': 'A1'}, {'operation': 'blow_out', 'pipette': 'p300_single', 'labware': 'opentrons_96_tiprack_300ul', 'well': 'A1'}, {'operation': 'drop_tip', 'pipette': 'p300_single', 'tiprack': 'opentrons_96_tiprack_300ul', 'well': 'A1'}]}, 'id': 'call_50Jlt2MFHDFRceSL6j1MYrCo', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1009, 'output_tokens': 526, 'total_tokens': 1535}), ToolMessage(content=\"{'deck_state': {'pipettes': {'left': 'p300_single'}, 'labware': {'1': '96-well plate corning', '7': 'thermocyclerModuleV2'}, 'tip_racks': {'2': 'opentrons_96_tiprack_300ul'}, 'modules': {'7': 'thermocyclerModuleV2'}}, 'workflow': [{'operation': 'load_labware', 'labware': '96-well plate corning', 'slot': '1'}, {'operation': 'load_module', 'module': 'thermocyclerModuleV2', 'slot': '7'}, {'operation': 'set_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'wait_until_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'load_pipette', 'pipette': 'p300_single', 'mount': 'left'}, {'operation': 'pick_up_tip', 'pipette': 'p300_single', 'tiprack': 'opentrons_96_tiprack_300ul', 'well': 'A1'}, {'operation': 'aspirate', 'pipette': 'p300_single', 'volume': 20, 'labware': '96-well plate corning', 'well': 'A1'}, {'operation': 'dispense', 'pipette': 'p300_single', 'volume': 20, 'labware': 'thermocyclerModuleV2', 'well': 'A1'}, {'operation': 'blow_out', 'pipette': 'p300_single', 'labware': 'opentrons_96_tiprack_300ul', 'well': 'A1'}, {'operation': 'drop_tip', 'pipette': 'p300_single', 'tiprack': 'opentrons_96_tiprack_300ul', 'well': 'A1'}]}\", name='OpentronsInstructions', tool_call_id='call_50Jlt2MFHDFRceSL6j1MYrCo'), AIMessage(content=\"```python\\nfrom opentrons import protocol_api\\n\\n# Metadata is a dictionary of data that is read by the server and returned to the opentrons app. \\n# Update these fields with your details.\\nmetadata = {\\n    'protocolName': 'My Protocol',\\n    'author': 'Your Name',\\n    'description': 'Simple protocol to get started using OT2',\\n    'apiLevel': '2.10'\\n}\\n\\ndef run(protocol: protocol_api.ProtocolContext):\\n\\n    # labware\\n    plate = protocol.load_labware('96-well plate corning', '1')\\n    tiprack = protocol.load_labware('opentrons_96_tiprack_300ul', '2')\\n\\n    # module\\n    thermocycler = protocol.load_module('thermocyclerModuleV2', '7')\\n\\n    # pipette\\n    pipette = protocol.load_instrument('p300_single', 'left', tip_racks=[tiprack])\\n\\n    # Set the thermocycler's temperature to 90C and wait until it reaches the target temperature\\n    thermocycler.set_temperature(90)\\n    thermocycler.await_temperature(90)\\n\\n    # Pick up a tip\\n    pipette.pick_up_tip(tiprack.wells_by_name()['A1'])\\n\\n    # Aspirate 20uL from the 96-well plate\\n    pipette.aspirate(20, plate.wells_by_name()['A1'])\\n\\n    # Dispense 20uL into the thermocycler\\n    pipette.dispense(20, thermocycler.wells_by_name()['A1'])\\n\\n    # Blow out the remaining liquid in the pipette into the tip rack\\n    pipette.blow_out(tiprack.wells_by_name()['A1'])\\n\\n    # Drop the tip back into the tip rack\\n    pipette.drop_tip(tiprack.wells_by_name()['A1'])\\n```\\n\"), HumanMessage(content='Please drop the tip in the tip rack and the blow out should happen in the thermocycler well A1'), AIMessage(content=\"```python\\nfrom opentrons import protocol_api\\n\\n# Metadata is a dictionary of data that is read by the server and returned to the opentrons app. \\n# Update these fields with your details.\\nmetadata = {\\n    'protocolName': 'My Protocol',\\n    'author': 'Your Name',\\n    'description': 'Simple protocol to get started using OT2',\\n    'apiLevel': '2.10'\\n}\\n\\ndef run(protocol: protocol_api.ProtocolContext):\\n\\n    # labware\\n    plate = protocol.load_labware('96-well plate corning', '1')\\n    tiprack = protocol.load_labware('opentrons_96_tiprack_300ul', '2')\\n\\n    # module\\n    thermocycler = protocol.load_module('thermocyclerModuleV2', '7')\\n\\n    # pipette\\n    pipette = protocol.load_instrument('p300_single', 'left', tip_racks=[tiprack])\\n\\n    # Set the thermocycler's temperature to 90C and wait until it reaches the target temperature\\n    thermocycler.set_temperature(90)\\n    thermocycler.await_temperature(90)\\n\\n    # Pick up a tip\\n    pipette.pick_up_tip(tiprack.wells_by_name()['A1'])\\n\\n    # Aspirate 20uL from the 96-well plate\\n    pipette.aspirate(20, plate.wells_by_name()['A1'])\\n\\n    # Dispense 20uL into the thermocycler\\n    pipette.dispense(20, thermocycler.wells_by_name()['A1'])\\n\\n    # Blow out the remaining liquid in the pipette into the thermocycler\\n    pipette.blow_out(thermocycler.wells_by_name()['A1'])\\n\\n    # Drop the tip back into the tip rack\\n    pipette.drop_tip()\\n```\", response_metadata={'token_usage': {'completion_tokens': 381, 'prompt_tokens': 1814, 'total_tokens': 2195}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8eeb4656-9300-4ab3-808a-9f0e700c8175-0', usage_metadata={'input_tokens': 1814, 'output_tokens': 381, 'total_tokens': 2195})]\n",
      "\n",
      "================================== Current Code ==================================\n",
      "```python\n",
      "from opentrons import protocol_api\n",
      "\n",
      "# Metadata is a dictionary of data that is read by the server and returned to the opentrons app. \n",
      "# Update these fields with your details.\n",
      "metadata = {\n",
      "    'protocolName': 'My Protocol',\n",
      "    'author': 'Your Name',\n",
      "    'description': 'Simple protocol to get started using OT2',\n",
      "    'apiLevel': '2.10'\n",
      "}\n",
      "\n",
      "def run(protocol: protocol_api.ProtocolContext):\n",
      "\n",
      "    # labware\n",
      "    plate = protocol.load_labware('96-well plate corning', '1')\n",
      "    tiprack = protocol.load_labware('opentrons_96_tiprack_300ul', '2')\n",
      "\n",
      "    # module\n",
      "    thermocycler = protocol.load_module('thermocyclerModuleV2', '7')\n",
      "\n",
      "    # pipette\n",
      "    pipette = protocol.load_instrument('p300_single', 'left', tip_racks=[tiprack])\n",
      "\n",
      "    # Set the thermocycler's temperature to 90C and wait until it reaches the target temperature\n",
      "    thermocycler.set_temperature(90)\n",
      "    thermocycler.await_temperature(90)\n",
      "\n",
      "    # Pick up a tip\n",
      "    pipette.pick_up_tip(tiprack.wells_by_name()['A1'])\n",
      "\n",
      "    # Aspirate 20uL from the 96-well plate\n",
      "    pipette.aspirate(20, plate.wells_by_name()['A1'])\n",
      "\n",
      "    # Dispense 20uL into the thermocycler\n",
      "    pipette.dispense(20, thermocycler.wells_by_name()['A1'])\n",
      "\n",
      "    # Blow out the remaining liquid in the pipette into the thermocycler\n",
      "    pipette.blow_out(thermocycler.wells_by_name()['A1'])\n",
      "\n",
      "    # Drop the tip back into the tip rack\n",
      "    pipette.drop_tip()\n",
      "```\n",
      "\n",
      "\n",
      "Done!\n",
      "AI: Goodbye!\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "default_config = \"\"\"\n",
    "{\n",
    "    \"pipettes\": {\n",
    "        \"left\": \"p300_single\",\n",
    "        \"right\": \"p10_single\"\n",
    "    },\n",
    "    \"labware\": {\n",
    "    },\n",
    "    \"tip_racks\": {\n",
    "    },\n",
    "    \"modules\": {\n",
    "        \"7\": \"thermocyclerModuleV2\"\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "while True:\n",
    "    user = input(\"User (q/Q to quit): \")\n",
    "    if user.lower() == 'q':\n",
    "        print(\"AI: Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    print(f\"\\n================================== Human message ==================================\\n{user}\\n\")\n",
    "\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=user)],\n",
    "        \"default_config\": default_config,\n",
    "        \"processed_command\": \"\",\n",
    "        \"awaiting_human_input\": False,\n",
    "        \"current_code\": \"\",\n",
    "        \"code_to_run\": \"\"\n",
    "    }\n",
    "\n",
    "    output = None\n",
    "    for output in graph.stream(initial_state, config=config):\n",
    "        if \"messages\" in output:\n",
    "            output[\"messages\"][-1].pretty_print()\n",
    "        \n",
    "        if output.get(\"awaiting_human_input\", False):\n",
    "            break  # Exit the loop to allow user input for code refinement\n",
    "\n",
    "    if output:\n",
    "        if \"code_to_run\" in output:\n",
    "            print(\"\\nFinal Approved Code:\")\n",
    "            print(output[\"code_to_run\"])\n",
    "            # Here you could add logic to actually run the code if needed\n",
    "        elif \"current_code\" in output:\n",
    "            print(\"\\nCurrent Code (not yet approved):\")\n",
    "            print(output[\"current_code\"])\n",
    "\n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent-lab-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
