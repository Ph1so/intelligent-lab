{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langgraph notebook 2\n",
    "https://langchain-ai.github.io/langgraph/\n",
    "\n",
    "Building agents from graphs\n",
    "\n",
    "In this notebook we first have a smaller model \"rephrase\" the user command before passing it to a bigger model. We also let the user specify a default config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from typing import TypedDict, Dict, List, Any, Optional\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage, BaseMessage\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the state\n",
    "class AgentState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    default_config: str\n",
    "    processed_command: str\n",
    "    awaiting_human_input: bool\n",
    "\n",
    "# Define Opentrons-specific models\n",
    "class PipetteInfo(BaseModel):\n",
    "    type: str\n",
    "    tip_rack: Optional[str] = None\n",
    "\n",
    "class OpentronsDeckState(BaseModel):\n",
    "    \"\"\"Information about the current state of the Opentrons deck.\"\"\"\n",
    "    pipettes: Dict[str, PipetteInfo] = Field(default_factory=dict, description=\"Pipettes attached to the robot, e.g., {'left': 'p300_single', 'right': 'p1000_multi'}\")\n",
    "    labware: Dict[str, str] = Field(default_factory=dict, description=\"Labware on the deck, e.g., {'1': 'opentrons_24_tuberack_eppendorf_1.5ml_safelock_snapcap'}\")\n",
    "    tip_racks: Dict[str, str] = Field(default_factory=dict, description=\"Tip racks on the deck, e.g., {'2': 'opentrons_96_tiprack_300ul'}\")\n",
    "    modules: Dict[str, str] = Field(default_factory=dict, description=\"Modules attached to the deck, e.g., {'7': 'thermocycler'}\")\n",
    "\n",
    "class OpentronsInstructions(BaseModel):\n",
    "    \"\"\"Flexible instructions for Opentrons liquid handling tasks.\"\"\"\n",
    "    workflow: List[Dict[str, Any]]  # A list of steps in the workflow\n",
    "    deck_state: OpentronsDeckState"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_processing_template = \"\"\"\n",
    "Analyze the user's Opentrons liquid handling command and provide a structured summary. Your response should be in YAML format with the following structure:\n",
    "\n",
    "command: \"A clear, specific restatement of the user's command\"\n",
    "task_breakdown:\n",
    "  - \"Step 1: ...\"\n",
    "  - \"Step 2: ...\"\n",
    "  - ...\n",
    "required_resources:\n",
    "  pipettes: []\n",
    "  labware: []\n",
    "  modules: []\n",
    "  reagents: []\n",
    "variables_to_specify:\n",
    "  - \"Variable 1: ...\"\n",
    "  - \"Variable 2: ...\"\n",
    "  - ...\n",
    "\n",
    "Focus on identifying all necessary components and variables crucial for task execution. Use Opentrons-specific language in the task breakdown. Only include variables that are critical and not specified in the original command.\n",
    "\n",
    "Examples:\n",
    "\n",
    "User input: \"Dilute all of the wells on the 96-well plate on deck slot 3 with 10 uL of water from a water container in well 1a of the 24-well metal block on top of the temperature controller. 20 uL tip rack is on deck slot 2 and the 20 uL pipette is mounted on the left side.\"\n",
    "\n",
    "Output:\n",
    "command: \"Dilute each well of a 96-well plate with 10 µL of water, using a 20 µL pipette and a temperature-controlled water source\"\n",
    "task_breakdown:\n",
    "  - \"1. Load labware onto the deck: 96-well plate, 24-well aluminum block, and 20 µL tip rack\"\n",
    "  - \"2. Load 20 µL single-channel pipette on the left mount\"\n",
    "  - \"3. Load temperature module and place 24-well metal block on it\"\n",
    "  - \"4. Load liquid (water) to well A1 of the 24-well metal block\"\n",
    "  - \"5. For each well in the 96-well plate:\"\n",
    "  - \"   a. Pick up a 20 µL tip\"\n",
    "  - \"   b. Aspirate 10 µL of water from well A1 of the 24-well block\"\n",
    "  - \"   c. Dispense 10 µL into the current well of the 96-well plate\"\n",
    "  - \"   d. Drop the used tip\"\n",
    "required_resources:\n",
    "  pipettes:\n",
    "    - \"20 µL single-channel (left)\"\n",
    "  labware:\n",
    "    - \"96-well plate\"\n",
    "    - \"24-well aluminum block\"\n",
    "    - \"20 µL tip rack\"\n",
    "  modules:\n",
    "    - \"Temperature module\"\n",
    "  reagents:\n",
    "    - \"Water\"\n",
    "variables_to_specify:\n",
    "  - \"Total volume of water needed for dilution\"\n",
    "\n",
    "User input: \"Transfer 5 uL from well A1 to B1 in the same plate and dispose of the tip\"\n",
    "\n",
    "Output:\n",
    "command: \"Transfer 5 µL from well A1 to well B1 within a single plate using a single-channel pipette, then dispose of the tip\"\n",
    "task_breakdown:\n",
    "  - \"1. Load labware onto the deck: plate and tip rack\"\n",
    "  - \"2. Load single-channel pipette (≤10 µL capacity)\"\n",
    "  - \"3. Pick up a pipette tip\"\n",
    "  - \"4. Aspirate 5 µL from well A1 of the plate\"\n",
    "  - \"5. Dispense 5 µL into well B1 of the same plate\"\n",
    "  - \"6. Drop the used tip in the trash\"\n",
    "required_resources:\n",
    "  pipettes:\n",
    "    - \"Single-channel pipette (≤10 µL capacity)\"\n",
    "  labware:\n",
    "    - \"Plate\"\n",
    "    - \"Tip rack\"\n",
    "  modules: []\n",
    "  reagents: []\n",
    "variables_to_specify:\n",
    "  - \"Plate location on deck\"\n",
    "  - \"Tip rack location on deck\"\n",
    "  - \"Pipette mount position (left or right)\"\n",
    "\n",
    "Provide a similar structured output for the given user input.\n",
    "\"\"\"\n",
    "\n",
    "get_info_template = \"\"\"\n",
    "Your task is to determine if more information is needed to execute the Opentrons liquid handling task. Review the rephrased command, task breakdown, required resources, variables to specify, default configuration, and conversation history.\n",
    "\n",
    "Analyze the information for:\n",
    "- Missing required resources\n",
    "- Unspecified critical variables (e.g., volumes, labware locations, pipette types and positions)\n",
    "- Compatibility issues between specified labware and pipettes\n",
    "- Any crucial information gaps that could prevent the protocol from running\n",
    "\n",
    "If critical information is missing, formulate 1-3 clear, concise questions to gather this information from the user. Focus only on what's absolutely necessary for the protocol to run correctly.\n",
    "\n",
    "If all critical information is available, use the OpentronsInstructions tool to generate instructions.\n",
    "\n",
    "Your response should be in one of these two formats:\n",
    "1. A list of questions, each on a new line, starting with \"Q: \". For example:\n",
    "   Q: What is the specific model of the 96-well plate?\n",
    "   Q: What is the configuration of the thermocycler plate?\n",
    "\n",
    "2. Or, if all information is complete, use the OpentronsInstructions tool to structure the information. Here's how to use the tool:\n",
    "\n",
    "1. Only use the tool when you have gathered ALL necessary information for the task.\n",
    "2. Structure the information into 'workflow' and 'deck_state' as defined by the tool.\n",
    "3. For 'workflow', provide a list of discrete steps, each with an 'operation' and relevant parameters.\n",
    "4. For 'deck_state', include information about pipettes, labware, tip_racks, and modules.\n",
    "5. If any information is assumed or inferred, clearly state these assumptions before using the tool.\n",
    "6. Do not include any fields or structures not defined in the OpentronsInstructions tool.\n",
    "\n",
    "Avoid asking about:\n",
    "- Exact labware models unless crucial for the protocol\n",
    "- Minor details that can be assumed based on standard laboratory practices\n",
    "- Information already provided in the default configuration unless there's a clear conflict\n",
    "\n",
    "Remember, output ONLY the questions or the tool use instruction, without any additional explanation or analysis.\n",
    "\"\"\"\n",
    "\n",
    "code_gen_template = \"\"\"\n",
    "Based on the following Opentrons workflow and deck state, generate Python code using the Opentrons API:\n",
    "\n",
    "{instructions}\n",
    "\n",
    "Ensure the code follows best practices for the Opentrons API, includes proper error handling, and is well-commented for clarity.\n",
    "\n",
    "Output just the commented code without any explanations or additional text. The user should be able to copy and paste the code into their Python script and run it without any modifications.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up models and chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_processing_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", initial_processing_template),\n",
    "    (\"human\", \"{input}\\n\\nDefault Opentrons config:\\n{default_config}\")\n",
    "])\n",
    "initial_processing_model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "initial_processing_chain = initial_processing_prompt | initial_processing_model\n",
    "\n",
    "get_info_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", get_info_template),\n",
    "    (\"human\", \"Initial command:\\n{initial_user_command}\\n\\nProcessed command:\\n{processed_command}\\n\\nDefault config:\\n{default_config}\"),\n",
    "    MessagesPlaceholder(variable_name=\"follow_up_messages\"),\n",
    "])\n",
    "get_info_model = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "get_info_model_with_tool = get_info_model.bind_tools([OpentronsInstructions])\n",
    "get_info_chain = (\n",
    "    {\n",
    "        \"initial_user_command\": lambda x: x[\"initial_user_command\"],\n",
    "        \"processed_command\": lambda x: x[\"processed_command\"],\n",
    "        \"default_config\": lambda x: x[\"default_config\"],\n",
    "        \"follow_up_messages\": lambda x: x[\"follow_up_messages\"]\n",
    "    }\n",
    "    | get_info_prompt\n",
    "    | get_info_model_with_tool\n",
    ")\n",
    "\n",
    "code_gen_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", code_gen_template),\n",
    "    (\"human\", \"{instructions}\")\n",
    "])\n",
    "code_gen_model = ChatOpenAI(model=\"gpt-4\", temperature=0)\n",
    "code_gen_chain = code_gen_prompt | code_gen_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define node functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_processing_node(state: AgentState):\n",
    "    processed_command = initial_processing_chain.invoke({\n",
    "        \"input\": state[\"messages\"][-1].content,\n",
    "        \"default_config\": state[\"default_config\"]\n",
    "    })\n",
    "    return {\n",
    "        \"processed_command\": processed_command.content,\n",
    "        \"messages\": state[\"messages\"] + [AIMessage(content=processed_command.content)]\n",
    "    }\n",
    "\n",
    "def get_info_node(state: AgentState):\n",
    "    initial_user_command = state[\"messages\"][0].content if state[\"messages\"] else \"\"\n",
    "    follow_up_messages = state[\"messages\"][2:] if len(state[\"messages\"]) > 2 else []\n",
    "    \n",
    "    result = get_info_chain.invoke({\n",
    "        \"initial_user_command\": initial_user_command,\n",
    "        \"processed_command\": state[\"processed_command\"],\n",
    "        \"default_config\": state[\"default_config\"],\n",
    "        \"follow_up_messages\": follow_up_messages\n",
    "    })\n",
    "\n",
    "    if isinstance(result, AIMessage) and result.tool_calls:\n",
    "        # If the content is empty, add a default message\n",
    "        if not result.content:\n",
    "            result.content = \"Using the OpentronsInstructions tool to generate the protocol.\"\n",
    "        \n",
    "        # Handle tool calls\n",
    "        tool_messages = []\n",
    "        for tool_call in result.tool_calls:\n",
    "            if tool_call['name'] == \"OpentronsInstructions\":\n",
    "                # Execute the OpentronsInstructions tool\n",
    "                tool_result = OpentronsInstructions(**tool_call['args'])\n",
    "                tool_message = ToolMessage(\n",
    "                    content=str(tool_result),\n",
    "                    tool_call_id=tool_call['id'],\n",
    "                    name=\"OpentronsInstructions\"\n",
    "                )\n",
    "                tool_messages.append(tool_message)\n",
    "        \n",
    "        print(f\"\\n================================== AI tool call ==================================\\n{[msg.content for msg in tool_messages]}\\n\")\n",
    "        return {\"messages\": state[\"messages\"] + [result] + tool_messages, \"awaiting_human_input\": False}\n",
    "    elif isinstance(result, (str, AIMessage)):\n",
    "        new_message = result if isinstance(result, AIMessage) else AIMessage(content=result)\n",
    "        print(f\"\\n================================== AI message ==================================\\n{new_message.content}\\n\")\n",
    "        user_input = input(\"User (q/Q to quit): \")\n",
    "        print(f\"\\n================================== Human message ==================================\\n{user_input}\\n\")\n",
    "        return {\n",
    "            \"messages\": state[\"messages\"] + [new_message, HumanMessage(content=user_input)],\n",
    "            \"awaiting_human_input\": False\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(f\"Unexpected result type: {type(result)}\")\n",
    "    \n",
    "def code_gen_node(state: AgentState):\n",
    "    instructions = next(msg.content for msg in reversed(state[\"messages\"]) if isinstance(msg, ToolMessage))\n",
    "    code = code_gen_chain.invoke({\"instructions\": instructions})\n",
    "    print(f\"\\n================================== AI message ==================================\\n{code.content}\\n\")\n",
    "    return {\"messages\": state[\"messages\"] + [AIMessage(content=code.content)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"initial_processing\", initial_processing_node)\n",
    "workflow.add_node(\"get_info\", get_info_node)\n",
    "workflow.add_node(\"code_gen\", code_gen_node)\n",
    "\n",
    "workflow.add_edge(START, \"initial_processing\")\n",
    "workflow.add_edge(\"initial_processing\", \"get_info\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"get_info\",\n",
    "    lambda x: \"code_gen\" if any(isinstance(m, ToolMessage) for m in x[\"messages\"]) else \"get_info\"\n",
    ")\n",
    "workflow.add_edge(\"code_gen\", END)\n",
    "\n",
    "# Compile the graph\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# Visualization (if in a Jupyter environment)\n",
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main execution loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================== Human message ==================================\n",
      "Please set the temperature of the thermocycler in deck slot 7 to 90 degC. After it has reached that temp, please transfer 20 uL from well 1A of a 96 well plate in slot 1 to the plate on the thermocycler (same well). Blow out tip and then discard the tip.\n",
      "\n",
      "\n",
      "================================== AI message ==================================\n",
      "Q: What type of 96-well plate are you using?\n",
      "Q: Where are the pipette tips located on the deck?\n",
      "\n",
      "\n",
      "================================== Human message ==================================\n",
      "Corning 96 well plate. 300 uL tips in deck slot 2.\n",
      "\n",
      "\n",
      "================================== AI tool call ==================================\n",
      "[\"workflow=[{'operation': 'load_labware', 'labware': 'corning_96_wellplate_360ul_flat', 'slot': '1'}, {'operation': 'load_module', 'module': 'thermocyclerModuleV2', 'slot': '7'}, {'operation': 'set_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'wait_until_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'load_pipette', 'pipette': 'p300_single', 'mount': 'left'}, {'operation': 'pick_up_tip', 'pipette': 'p300_single', 'tip_rack': '2'}, {'operation': 'aspirate', 'pipette': 'p300_single', 'volume': 20, 'labware': 'corning_96_wellplate_360ul_flat', 'well': 'A1'}, {'operation': 'dispense', 'pipette': 'p300_single', 'volume': 20, 'labware': 'thermocyclerModuleV2', 'well': 'A1'}, {'operation': 'blow_out', 'pipette': 'p300_single'}, {'operation': 'drop_tip', 'pipette': 'p300_single'}] deck_state=OpentronsDeckState(pipettes={'left': PipetteInfo(type='p300_single', tip_rack='2')}, labware={'1': 'corning_96_wellplate_360ul_flat', '2': 'opentrons_tiprack_300ul', '7': 'thermocyclerModuleV2'}, tip_racks={}, modules={'7': 'thermocyclerModuleV2'})\"]\n",
      "\n",
      "Full state before code generation: {'messages': [HumanMessage(content='Please set the temperature of the thermocycler in deck slot 7 to 90 degC. After it has reached that temp, please transfer 20 uL from well 1A of a 96 well plate in slot 1 to the plate on the thermocycler (same well). Blow out tip and then discard the tip.'), AIMessage(content='```yaml\\ncommand: \"Set the thermocycler temperature to 90 °C, then transfer 20 µL from well 1A of a 96-well plate in slot 1 to the same well on the thermocycler, blow out the tip, and discard it.\"\\ntask_breakdown:\\n  - \"1. Load labware onto the deck: 96-well plate in slot 1\"\\n  - \"2. Load the thermocycler module in deck slot 7\"\\n  - \"3. Set the thermocycler temperature to 90 °C\"\\n  - \"4. Wait until the thermocycler reaches 90 °C\"\\n  - \"5. Load a pipette (p300_single) on the left mount\"\\n  - \"6. Pick up a pipette tip\"\\n  - \"7. Aspirate 20 µL from well 1A of the 96-well plate in slot 1\"\\n  - \"8. Dispense 20 µL into well 1A of the thermocycler\"\\n  - \"9. Blow out the tip to ensure all liquid is dispensed\"\\n  - \"10. Drop the used tip in the trash\"\\nrequired_resources:\\n  pipettes:\\n    - \"p300_single (left)\"\\n  labware:\\n    - \"96-well plate\"\\n  modules:\\n    - \"thermocyclerModuleV2\"\\n  reagents: []\\nvariables_to_specify:\\n  - \"Location of the 96-well plate on deck (slot 1)\"\\n  - \"Thermocycler well location for transfer (well 1A)\"\\n```'), AIMessage(content='Q: What type of 96-well plate are you using?\\nQ: Where are the pipette tips located on the deck?', response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 978, 'total_tokens': 1006}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-92121e0a-1a4c-4a03-b4b4-641b616cb721-0', usage_metadata={'input_tokens': 978, 'output_tokens': 28, 'total_tokens': 1006}), HumanMessage(content='Corning 96 well plate. 300 uL tips in deck slot 2.'), AIMessage(content='Using the OpentronsInstructions tool to generate the protocol.', additional_kwargs={'tool_calls': [{'id': 'call_HWrFWpfGP3lLT6My0bt8Ml5q', 'function': {'arguments': '{\\n  \"deck_state\": {\\n    \"pipettes\": {\\n      \"left\": {\\n        \"type\": \"p300_single\",\\n        \"tip_rack\": \"2\"\\n      }\\n    },\\n    \"labware\": {\\n      \"1\": \"corning_96_wellplate_360ul_flat\",\\n      \"2\": \"opentrons_tiprack_300ul\",\\n      \"7\": \"thermocyclerModuleV2\"\\n    },\\n    \"modules\": {\\n      \"7\": \"thermocyclerModuleV2\"\\n    }\\n  },\\n  \"workflow\": [\\n    {\\n      \"operation\": \"load_labware\",\\n      \"labware\": \"corning_96_wellplate_360ul_flat\",\\n      \"slot\": \"1\"\\n    },\\n    {\\n      \"operation\": \"load_module\",\\n      \"module\": \"thermocyclerModuleV2\",\\n      \"slot\": \"7\"\\n    },\\n    {\\n      \"operation\": \"set_temperature\",\\n      \"module\": \"thermocyclerModuleV2\",\\n      \"temperature\": 90\\n    },\\n    {\\n      \"operation\": \"wait_until_temperature\",\\n      \"module\": \"thermocyclerModuleV2\",\\n      \"temperature\": 90\\n    },\\n    {\\n      \"operation\": \"load_pipette\",\\n      \"pipette\": \"p300_single\",\\n      \"mount\": \"left\"\\n    },\\n    {\\n      \"operation\": \"pick_up_tip\",\\n      \"pipette\": \"p300_single\",\\n      \"tip_rack\": \"2\"\\n    },\\n    {\\n      \"operation\": \"aspirate\",\\n      \"pipette\": \"p300_single\",\\n      \"volume\": 20,\\n      \"labware\": \"corning_96_wellplate_360ul_flat\",\\n      \"well\": \"A1\"\\n    },\\n    {\\n      \"operation\": \"dispense\",\\n      \"pipette\": \"p300_single\",\\n      \"volume\": 20,\\n      \"labware\": \"thermocyclerModuleV2\",\\n      \"well\": \"A1\"\\n    },\\n    {\\n      \"operation\": \"blow_out\",\\n      \"pipette\": \"p300_single\"\\n    },\\n    {\\n      \"operation\": \"drop_tip\",\\n      \"pipette\": \"p300_single\"\\n    }\\n  ]\\n}', 'name': 'OpentronsInstructions'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 480, 'prompt_tokens': 1031, 'total_tokens': 1511}, 'model_name': 'gpt-4-0613', 'system_fingerprint': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-a5fa306d-704c-48bd-a138-5e020e6953ed-0', tool_calls=[{'name': 'OpentronsInstructions', 'args': {'deck_state': {'pipettes': {'left': {'type': 'p300_single', 'tip_rack': '2'}}, 'labware': {'1': 'corning_96_wellplate_360ul_flat', '2': 'opentrons_tiprack_300ul', '7': 'thermocyclerModuleV2'}, 'modules': {'7': 'thermocyclerModuleV2'}}, 'workflow': [{'operation': 'load_labware', 'labware': 'corning_96_wellplate_360ul_flat', 'slot': '1'}, {'operation': 'load_module', 'module': 'thermocyclerModuleV2', 'slot': '7'}, {'operation': 'set_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'wait_until_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'load_pipette', 'pipette': 'p300_single', 'mount': 'left'}, {'operation': 'pick_up_tip', 'pipette': 'p300_single', 'tip_rack': '2'}, {'operation': 'aspirate', 'pipette': 'p300_single', 'volume': 20, 'labware': 'corning_96_wellplate_360ul_flat', 'well': 'A1'}, {'operation': 'dispense', 'pipette': 'p300_single', 'volume': 20, 'labware': 'thermocyclerModuleV2', 'well': 'A1'}, {'operation': 'blow_out', 'pipette': 'p300_single'}, {'operation': 'drop_tip', 'pipette': 'p300_single'}]}, 'id': 'call_HWrFWpfGP3lLT6My0bt8Ml5q', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1031, 'output_tokens': 480, 'total_tokens': 1511}), ToolMessage(content=\"workflow=[{'operation': 'load_labware', 'labware': 'corning_96_wellplate_360ul_flat', 'slot': '1'}, {'operation': 'load_module', 'module': 'thermocyclerModuleV2', 'slot': '7'}, {'operation': 'set_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'wait_until_temperature', 'module': 'thermocyclerModuleV2', 'temperature': 90}, {'operation': 'load_pipette', 'pipette': 'p300_single', 'mount': 'left'}, {'operation': 'pick_up_tip', 'pipette': 'p300_single', 'tip_rack': '2'}, {'operation': 'aspirate', 'pipette': 'p300_single', 'volume': 20, 'labware': 'corning_96_wellplate_360ul_flat', 'well': 'A1'}, {'operation': 'dispense', 'pipette': 'p300_single', 'volume': 20, 'labware': 'thermocyclerModuleV2', 'well': 'A1'}, {'operation': 'blow_out', 'pipette': 'p300_single'}, {'operation': 'drop_tip', 'pipette': 'p300_single'}] deck_state=OpentronsDeckState(pipettes={'left': PipetteInfo(type='p300_single', tip_rack='2')}, labware={'1': 'corning_96_wellplate_360ul_flat', '2': 'opentrons_tiprack_300ul', '7': 'thermocyclerModuleV2'}, tip_racks={}, modules={'7': 'thermocyclerModuleV2'})\", name='OpentronsInstructions', tool_call_id='call_HWrFWpfGP3lLT6My0bt8Ml5q')], 'default_config': '\\n{\\n    \"pipettes\": {\\n        \"left\": \"p300_single\",\\n        \"right\": \"p10_single\"\\n    },\\n    \"labware\": {\\n    },\\n    \"tip_racks\": {\\n    },\\n    \"modules\": {\\n        \"7\": \"thermocyclerModuleV2\"\\n    }\\n}\\n', 'processed_command': '```yaml\\ncommand: \"Set the thermocycler temperature to 90 °C, then transfer 20 µL from well 1A of a 96-well plate in slot 1 to the same well on the thermocycler, blow out the tip, and discard it.\"\\ntask_breakdown:\\n  - \"1. Load labware onto the deck: 96-well plate in slot 1\"\\n  - \"2. Load the thermocycler module in deck slot 7\"\\n  - \"3. Set the thermocycler temperature to 90 °C\"\\n  - \"4. Wait until the thermocycler reaches 90 °C\"\\n  - \"5. Load a pipette (p300_single) on the left mount\"\\n  - \"6. Pick up a pipette tip\"\\n  - \"7. Aspirate 20 µL from well 1A of the 96-well plate in slot 1\"\\n  - \"8. Dispense 20 µL into well 1A of the thermocycler\"\\n  - \"9. Blow out the tip to ensure all liquid is dispensed\"\\n  - \"10. Drop the used tip in the trash\"\\nrequired_resources:\\n  pipettes:\\n    - \"p300_single (left)\"\\n  labware:\\n    - \"96-well plate\"\\n  modules:\\n    - \"thermocyclerModuleV2\"\\n  reagents: []\\nvariables_to_specify:\\n  - \"Location of the 96-well plate on deck (slot 1)\"\\n  - \"Thermocycler well location for transfer (well 1A)\"\\n```', 'awaiting_human_input': False}\n",
      "\n",
      "================================== AI message ==================================\n",
      "```python\n",
      "from opentrons import protocol_api\n",
      "\n",
      "# Define the protocol function\n",
      "def run(protocol: protocol_api.ProtocolContext):\n",
      "\n",
      "    # Load labware\n",
      "    plate = protocol.load_labware('corning_96_wellplate_360ul_flat', '1')\n",
      "\n",
      "    # Load thermocycler module\n",
      "    thermocycler = protocol.load_module('thermocyclerModuleV2', '7')\n",
      "\n",
      "    # Set the temperature of the thermocycler\n",
      "    thermocycler.set_temperature(90)\n",
      "\n",
      "    # Wait until the thermocycler reaches the target temperature\n",
      "    thermocycler.await_temperature(90)\n",
      "\n",
      "    # Load pipette\n",
      "    pipette = protocol.load_instrument('p300_single', 'left')\n",
      "\n",
      "    # Load tip rack\n",
      "    tip_rack = protocol.load_labware('opentrons_tiprack_300ul', '2')\n",
      "\n",
      "    # Pick up tip\n",
      "    pipette.pick_up_tip(tip_rack.wells()[0])\n",
      "\n",
      "    # Aspirate from the well\n",
      "    pipette.aspirate(20, plate.wells_by_name()['A1'])\n",
      "\n",
      "    # Dispense to the thermocycler\n",
      "    pipette.dispense(20, thermocycler.wells_by_name()['A1'])\n",
      "\n",
      "    # Blow out\n",
      "    pipette.blow_out()\n",
      "\n",
      "    # Drop tip\n",
      "    pipette.drop_tip()\n",
      "```\n",
      "This code assumes that the thermocycler module is in slot 7 and the pipette is mounted on the left. The pipette aspirates from well A1 of the plate in slot 1 and dispenses into well A1 of the thermocycler. The pipette then blows out and drops the tip. The thermocycler is set to 90 degrees Celsius and the protocol waits until the thermocycler reaches this temperature before proceeding.\n",
      "\n",
      "\n",
      "Done!\n",
      "AI: Byebye\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "default_config = \"\"\"\n",
    "{\n",
    "    \"pipettes\": {\n",
    "        \"left\": \"p300_single\",\n",
    "        \"right\": \"p10_single\"\n",
    "    },\n",
    "    \"labware\": {\n",
    "    },\n",
    "    \"tip_racks\": {\n",
    "    },\n",
    "    \"modules\": {\n",
    "        \"7\": \"thermocyclerModuleV2\"\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "while True:\n",
    "    user = input(\"User (q/Q to quit): \")\n",
    "    if user in {\"q\", \"Q\"}:\n",
    "        print(\"AI: Byebye\")\n",
    "        break\n",
    "    \n",
    "    print(f\"\\n================================== Human message ==================================\\n{user}\\n\")\n",
    "\n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=user)],\n",
    "        \"default_config\": default_config,\n",
    "        \"processed_command\": \"\",\n",
    "        \"awaiting_human_input\": False\n",
    "    }\n",
    "\n",
    "    output = None\n",
    "    for output in graph.stream(initial_state, config=config):\n",
    "        if \"messages\" in output:\n",
    "            output[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intelligent-lab-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
